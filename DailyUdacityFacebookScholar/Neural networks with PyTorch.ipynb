{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import helper\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define a transform to normaalize the data\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               transforms.Normalize(mean = (0.5,), std = (0.5,)),\n",
    "                               ])\n",
    "\n",
    "\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('MNIST_data/', download = True, train = True, transform = transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True)\n",
    "\n",
    "# batch size: images we get in one iteration \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "#grabbing the first batch with \"next.()\"\n",
    "print(type(images))\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1240dddd8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([784])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[1].flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+torch.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 784])\n"
     ]
    }
   ],
   "source": [
    "inputs = images.view(images.shape[0], -1) # 64, 784\n",
    "# grab the # of batches and flattened vector\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.9998e-01, 9.9988e-01, 8.3809e-20,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        [9.3644e-02, 9.9411e-01, 9.9981e-01,  ..., 1.0000e+00, 9.2459e-01,\n",
      "         1.8411e-01],\n",
      "        [6.9667e-01, 1.0000e+00, 5.1780e-08,  ..., 1.0000e+00, 1.0000e+00,\n",
      "         1.0000e+00],\n",
      "        ...,\n",
      "        [3.5103e-21, 9.9999e-01, 1.8186e-18,  ..., 1.0000e+00, 1.6855e-10,\n",
      "         1.0000e+00],\n",
      "        [2.5547e-05, 9.9968e-01, 3.0541e-14,  ..., 1.0000e+00, 9.9387e-01,\n",
      "         1.0000e+00],\n",
      "        [2.2308e-02, 7.3076e-01, 7.7308e-13,  ..., 1.0000e+00, 6.0558e-02,\n",
      "         1.0000e+00]])\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "w1 = torch.randn(inputs.shape[1], 256)\n",
    "#print(w1.shape)\n",
    "b1 = torch.randn(256)\n",
    "\n",
    "w2 = torch.randn(256, 10)\n",
    "b2 = torch.randn(10)\n",
    "\n",
    "h = activation(torch.mm(inputs, w1) + b1)\n",
    "print(h)\n",
    "out = activation(torch.mm(h, w2)+ b2)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmx(arry):\n",
    "    deno = 0\n",
    "    for i in arry:\n",
    "        deno += i\n",
    "    return arry/deno\n",
    "def softMX(mat):\n",
    "    tmp = []\n",
    "    for j in range(mat.shape[0]):\n",
    "        tmp.append(softmx(j))\n",
    "    return tmp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.6349e-04, 1.2182e-04, 9.9848e-01, 1.0506e-02, 1.8243e-05, 2.4714e-10,\n",
       "        5.3031e-04, 9.9981e-01, 9.6280e-01, 2.8912e-07])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5001e-05, 4.0984e-05, 3.3591e-01, 3.5345e-03, 6.1375e-06, 8.3145e-11,\n",
       "        1.7841e-04, 3.3636e-01, 3.2391e-01, 9.7267e-08])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmx(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Solution\n",
    "def softmax(x):\n",
    "    return torch.exp(x)/torch.sum(torch.exp(x), dim = 1).view(-1,1)\n",
    "probabilities = softmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "print(probabilities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000])\n"
     ]
    }
   ],
   "source": [
    "print(probabilities.sum(dim = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>[[[[Practice</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "sp = activation(torch.randn((3,5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5834, 0.5322, 0.5583, 0.5573, 0.2455],\n",
       "        [0.4536, 0.9010, 0.3457, 0.6134, 0.5664],\n",
       "        [0.6306, 0.6920, 0.7522, 0.1558, 0.2711]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.7921, 1.7026, 1.7478, 1.7460, 1.2782],\n",
       "        [1.5739, 2.4620, 1.4130, 1.8467, 1.7620],\n",
       "        [1.8788, 1.9977, 2.1216, 1.1686, 1.3114]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(sp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8.2667, 9.0576, 8.4781])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.exp(sp), dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.2448, 6.1623, 5.2824, 4.7613, 4.3517])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.exp(sp), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.2448],\n",
       "        [6.1623],\n",
       "        [5.2824],\n",
       "        [4.7613],\n",
       "        [4.3517]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(torch.exp(sp), dim = 0).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2168, 0.2060, 0.2114, 0.2112, 0.1546],\n",
       "        [0.1738, 0.2718, 0.1560, 0.2039, 0.1945],\n",
       "        [0.2216, 0.2356, 0.2502, 0.1378, 0.1547]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(sp)/torch.sum(torch.exp(sp), dim = 1).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = torch.exp(sp)/torch.sum(torch.exp(sp), dim = 1).view(-1,1)\n",
    "prob.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob.sum(dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>Pratice]]]]</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution\n",
    "# Build neural network\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #Inputs to hidden layer linear transformations\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        #Output layer, 10 units - one for each digit\n",
    "        self.output = nn.Linear(256,10)\n",
    "        \n",
    "        #Define sigmoid activation and softmax output\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax(dim = 1)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        #Pass the input tensor through each of our operations\n",
    "        x = self.hidden(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.output(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (hidden): Linear(in_features=784, out_features=256, bias=True)\n",
       "  (output): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Network()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another solution\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden = nn.Linear(784, 256)\n",
    "        self.output = nn.Linear(256,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.sigmoid(self.hidden(x))\n",
    "        x = F.softmax(self.output(x), dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment: Your Turn to Build a Network\n",
    "# input784, hidden1 128, hidden2 64, output10 \n",
    "# relu, relu, softmzx, cross-entropy\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(784, 128)\n",
    "        self.hidden2 = nn.Linear(128, 64)\n",
    "        self.output = nn.Linear(128,10)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = F.softmax(self.output(x), dim = 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
