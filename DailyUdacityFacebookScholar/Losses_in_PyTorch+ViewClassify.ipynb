{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /Users/yujinchung/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:02, 4293675.38it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/yujinchung/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /Users/yujinchung/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 51368.49it/s]                           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/yujinchung/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /Users/yujinchung/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:02, 722483.06it/s]                             \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/yujinchung/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /Users/yujinchung/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 19428.76it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/yujinchung/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean = (0.5,), std = (0.5,)),\n",
    "                                                     ])\n",
    "                                 \n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download = True, train = True, transform = transforms)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64,shuffle = True)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3146, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Build a feed_forward network \n",
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128,64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10))\n",
    "\n",
    "# Define the loss \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Get our daata \n",
    "images, labels = next(iter(trainloader))\n",
    "# flatten images \n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "# Forward pass, get our logits \n",
    "logits = model(images)\n",
    "\n",
    "# Calculate the loss with the logits and the labels \n",
    "loss = criterion(logits, labels)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Build a model that returns the log-softmax as the output<br>\n",
    "and calculate the loss using the negative log likelihood loss.<br>\n",
    "<p>\n",
    "Not that for nn.LogSoftmax and F.log_softmax you'll need to set the dim keyword argument appropriately.<br>\n",
    "\n",
    "dim = 0 calculates softmax across the rows, so each column sums to 1.<br>\n",
    "While dim = 1, calculates across the columns so each row sums to 1. <br>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2987, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64), \n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64, 10),\n",
    "                     nn.LogSoftmax(dim = 1))\n",
    "# last part, dim should be 1, bcs 10 class prob sum should be 1\n",
    "# if dim = 0, then 64 units' prob sum get to be 1, which is misleading.\n",
    "\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "logps= model(images)\n",
    "loss = criterion(logps, labels)\n",
    "\n",
    "print(loss) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before backward pass: \n",
      " None\n",
      "After backward pass: \n",
      " tensor([[0.0022, 0.0022, 0.0022,  ..., 0.0022, 0.0022, 0.0022],\n",
      "        [0.0005, 0.0005, 0.0005,  ..., 0.0005, 0.0005, 0.0005],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0019, 0.0019, 0.0019,  ..., 0.0019, 0.0019, 0.0019],\n",
      "        [0.0006, 0.0006, 0.0006,  ..., 0.0006, 0.0006, 0.0006],\n",
      "        [0.0009, 0.0009, 0.0009,  ..., 0.0009, 0.0009, 0.0009]])\n"
     ]
    }
   ],
   "source": [
    "print('Before backward pass: \\n', model[0].weight.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('After backward pass: \\n', model[0].weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the network!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "> update the weights with the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim \n",
    "# import optimizer from torch\n",
    "\n",
    "# Optimizers require the prameters to optimize and a learning rate \n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights -  Parameter containing:\n",
      "tensor([[ 0.0171,  0.0156,  0.0022,  ..., -0.0023, -0.0146, -0.0156],\n",
      "        [-0.0080, -0.0061, -0.0064,  ...,  0.0347,  0.0309,  0.0080],\n",
      "        [ 0.0191,  0.0107, -0.0004,  ..., -0.0003, -0.0215,  0.0256],\n",
      "        ...,\n",
      "        [-0.0296,  0.0065, -0.0263,  ..., -0.0168,  0.0118,  0.0240],\n",
      "        [ 0.0355,  0.0002,  0.0175,  ...,  0.0254,  0.0290,  0.0311],\n",
      "        [-0.0171, -0.0294,  0.0158,  ...,  0.0224,  0.0199, -0.0162]],\n",
      "       requires_grad=True)\n",
      "Gradient -  tensor([[ 0.0026,  0.0026,  0.0026,  ...,  0.0026,  0.0026,  0.0026],\n",
      "        [-0.0008, -0.0008, -0.0008,  ..., -0.0008, -0.0008, -0.0008],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0002,  0.0002,  0.0002,  ...,  0.0002,  0.0002,  0.0002],\n",
      "        [ 0.0006,  0.0006,  0.0006,  ...,  0.0006,  0.0006,  0.0006],\n",
      "        [ 0.0010,  0.0010,  0.0010,  ...,  0.0010,  0.0010,  0.0010]])\n"
     ]
    }
   ],
   "source": [
    "print('Initial weights - ', model[0].weight)\n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "images.resize_(64, 784)\n",
    "\n",
    "# Clear the gradients, do this becuase gradients are accumulated\n",
    "optimizer.zero_grad()\n",
    "output = model.forward(images)\n",
    "loss = criterion(output, labels)\n",
    "loss.backward()\n",
    "print('Gradient - ', model[0].weight.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weights -  Parameter containing:\n",
      "tensor([[ 0.0171,  0.0155,  0.0022,  ..., -0.0023, -0.0146, -0.0157],\n",
      "        [-0.0080, -0.0061, -0.0064,  ...,  0.0348,  0.0309,  0.0080],\n",
      "        [ 0.0191,  0.0107, -0.0004,  ..., -0.0003, -0.0215,  0.0256],\n",
      "        ...,\n",
      "        [-0.0296,  0.0065, -0.0263,  ..., -0.0168,  0.0118,  0.0240],\n",
      "        [ 0.0355,  0.0002,  0.0175,  ...,  0.0254,  0.0290,  0.0311],\n",
      "        [-0.0171, -0.0295,  0.0158,  ...,  0.0224,  0.0199, -0.0162]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# take an updates step and few the new weights\n",
    "optimizer.step()\n",
    "print('Updated weights - ', model[0].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 1.025889269769319\n",
      "Training loss: 0.38538900854935776\n",
      "Training loss: 0.32537676274045696\n",
      "Training loss: 0.29136236226444306\n",
      "Training loss: 0.2655929716061682\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(nn.Linear(784, 128),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(128, 64),\n",
    "                     nn.ReLU(),\n",
    "                     nn.Linear(64,10),\n",
    "                     nn.LogSoftmax(dim = 1))\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "\n",
    "\n",
    "# optimizer.zero_grad()\n",
    "# output = model.forward(images)\n",
    "# loss = criterion(output, labels)\n",
    "# loss.backward()\n",
    "# print('Gradient - ', model[0].weight.grad)\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        #Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        \n",
    "        # TODO: Training pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward() # NEVER FORGET to ADD ()!!!!!!!\n",
    "        optimizer.step() # I have missed this part \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    else:\n",
    "        print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline \n",
    "import helper \n",
    "\n",
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "# Turn off gradients to speed up this part \n",
    "with torch.no_grad():\n",
    "    logits = model.forward(img)\n",
    "    \n",
    "# Output of the network are logits, need to take softmax for probabilities \n",
    "ps = F.softmax(logits, dim = 1)\n",
    "view_classify(img.view(1,28,28), ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
